{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prevendo a Probabilidade de Ocorrência de Graves Acidentes de Trabalho Usando a Técnica Ensembles de Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![oi](esemble.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sumário"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Introdução](#1)\n",
    "* [Preparando os Dados](#2)\n",
    "* [Ensemble Machine Learning](#3)\n",
    "   - [One Level](#4)\n",
    "   - [Secund Level](#5)\n",
    "* [Ensemble Machine Learning](#6)\n",
    "* [Criando Dataframe Com as Previsões](#7)\n",
    "* [Conclusão](#8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução <a id= \"1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desenvolver um ambiente de trabalho protetor e o mais seguro possível é um dos principais desafios enfrentados pelas companhias. Principalmente Em setores pesados da indústria, onde o risco de acidente fatal é bem maior que nos demais setores. Naturalmente, a busca de ambiente de trabalho com alta prioridade de segurança pode custar um parte significativa da receita de uma companhia. Logo, buscar novas técnicas e tecnologias que aumente a eficiência da gestão de segurança do trabalho e ao mesmo tempo reduza os custos de implementação é imprescindível. Com este intuito, construir modelos de previsão que possam mostrar a probabilidade de ocorrência de determinados eventos de risco é uma estratégia muito empregada atualmente. Modelos de machine learning são muito bons em classificar e prever a probabilidade de eventos de risco. Contudo, devido a natureza delicada de se prever a possibilidade de um funcionário sofrer um acidente fatal, precisamos de modelos realmente confiáveis. Sabemos que um único modelo de machine laerning esta sujeito a eventos que podem reduzir ou invalidar suas previsões. Entre esses eventos temos os mais comuns que são o overfiting e underfiting. Além disso temos a possiblidade das features do dataset ser bastante heterogênea de modo que o modelo pode ter um desempenho melhor para determinadas partes do dataset do que em outras. \n",
    "\n",
    "Nosso objetivo é construir um modelo de classificação que possa prever com alta confiabilidade o 'grau de lesão' evitando a maioria dos problemas citados acima. Por isso faremos uso de esemble de machine learnig do tipo stacking que usa a previsão de vários modelos de machine leaining para gerar dados para validação posterior de outros modelos. Normalmente quando queremos validar informações que possuímos comparamos com outras fontes que possuem a mesma informação. Para uma visão mais detalhada do conceito ensemble pode ser encontrado aqui: [ensemble-learning-bagging-boosting-stacking](https://www.kaggle.com/satishgunjal/ensemble-learning-bagging-boosting-stacking). Quanto mais fontes puderem validar a nossa informação prévia mais certos estaremos. Esta é a forma básica de como a técnica dos esembles funciona, com isso esperamos aumentar a confiança na previsão dos nossos modelos. Mais especificamente nosso esemble terá dois níveis, onde rodamos um conjunto de modelos no primeiro nível e usamos as predições deste nível para treinar um modelo no segundo nível. De modo que o modelo de segundo nível deve ter um desepenho melhor e mais confiável que um único modelo.\n",
    "\n",
    "A nossa base de dados que usaremos neste notebook foi obtida do dataset original onde este consistia de uma série de colunas categóricas e numéricas que mostrava várias informações sobre os empregados que sofreram lesões fatais e não-fatais. O dataset original pode encontrado neste link: [Osha-accident-and-injury-data](https://www.kaggle.com/ruqaiyaship/osha-accident-and-injury-data-1517). Após as transformações adequadas para a limpeza do dataset, convertemos as features categóricas em novas colunas usando o OneHotEncoder(). Com os dados limpos em mãos tentaremos responder a seguinte questão: dado uma série de features associadas a um empregado que sofreu um acidente qual probabilidade do mesmo sobreviver ou não ao um determinado acidente de trabalho. Para avaliar todos os modelos utilizados neste notebook usaremos a métrica log-loss e a métrica ROC-AUC. A log-loss é a melhor métrica para avaliar classificação com base nas probabilidades das previsões. Além disso a log-loss é muito boa para compararmos modelos com outros, quando menor o valor da log-loss melhor será o modelo. Já ROC-AUC basicamente nos diz o quão bem o modelo conseguie separar as classes alvos. 50% de ROC-AUC significa que o modelo não consegue distinguir entre as classes alvos, enquanto que  em 100% o modelo separa com perfeição as classes alvos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando as bibliotecas necessárias\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler \n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import log_loss\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from colorama import Fore, Back, Style \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando os Dados <a id= \"2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Degree of Injury</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "      <th>build_stor</th>\n",
       "      <th>nature_of_inj</th>\n",
       "      <th>evn_factor</th>\n",
       "      <th>fat_cause</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 159 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Degree of Injury    0    1    2    3    4    5    6    7    8  ...  148  \\\n",
       "0                 0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "1                 0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  ...  0.0   \n",
       "2                 0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "\n",
       "   149  150  build_stor  nature_of_inj  evn_factor  fat_cause  Year  Month  \\\n",
       "0  0.0  0.0           0              1           2          0  2017      8   \n",
       "1  0.0  0.0           1              9          18          0  2017      7   \n",
       "2  0.0  0.0           0              5          18          0  2017      6   \n",
       "\n",
       "   Day  \n",
       "0   10  \n",
       "1   17  \n",
       "2   30  \n",
       "\n",
       "[3 rows x 159 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lendo os dados do dataset previamente limpo.\n",
    "df = pd.read_csv('oblivion.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nossa variável alvo é a coluna categórica 'Degree of Injury' que contem duas classes para nível do lesão que os empregados sofreram. A classe com valor 0 representada os empregados que sobreviveram ao acidente de trabalho, enquanto a classe com valor 1 representa os empregados que não sobreviveram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Verificando o desbalanceamento das classes 0 e 1 do 'Degree of Injury'.\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x = df['Degree of Injury']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfsAAAFzCAYAAAA5aKBnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAWMklEQVR4nO3df7DldX3f8efLXVDjLzBcKe6SLk3WdrDRFW8QYzo1EgGZSZYY4sBUWSnN2g44cWozg5lMsFpmTKPSQAwZUlbAMSKWGLd2p3RFq/khwl2yARZCuUUsuwPsDUvwV0q6m3f/OJ+NJ+vd3XPxnnv3fPb5mLlzv+fz/XE+l5nL836/57vnpKqQJEn9es5yT0CSJI2XsZckqXPGXpKkzhl7SZI6Z+wlSeqcsZckqXMrl3sC43DCCSfUmjVrlnsakiQtmW3btv1lVU3Nt67L2K9Zs4aZmZnlnoYkSUsmyTcOts7L+JIkdc7YS5LUOWMvSVLnjL0kSZ0z9pIkdW5ssU/yvCR3JvnzJDuS/Ps2fkqSryWZTfLpJMe28ee2x7Nt/ZqhY72vjT+Y5OxxzVmSpB6N88z+GeBNVfVqYB1wTpIzgN8ArqqqHwOeAi5p218CPNXGr2rbkeRU4ALglcA5wO8kWTHGeUuS1JWxxb4Gvt0eHtO+CngT8F/a+I3AeW15fXtMW39mkrTxm6vqmar6OjALnD6ueUuS1JuxvmafZEWS7cBuYCvwv4G/qqq9bZOdwKq2vAp4FKCtfxr44eHxefaRJEmHMdbYV9W+qloHrGZwNv5PxvVcSTYmmUkyMzc3N66nkSRp4izJ3fhV9VfAl4DXA8cl2f82vauBXW15F3AyQFv/EuDJ4fF59hl+juuqarqqpqem5n1rYEmSjkrjvBt/Kslxbfn5wJuBBxhE//y22Qbgc215c3tMW//Fqqo2fkG7W/8UYC1w57jmLUlSb8b5QTgnATe2O+efA9xSVZ9Pcj9wc5L/APwZcH3b/nrgE0lmgT0M7sCnqnYkuQW4H9gLXFpV+8Y4b0mSupLByXNfpqena1yfevfaX7lpLMeVltK237xouaewYP/nAz++3FOQFsWP/Pq9Yzlukm1VNT3fOt9BT5Kkzhl7SZI6Z+wlSeqcsZckqXPGXpKkzhl7SZI6Z+wlSeqcsZckqXPGXpKkzhl7SZI6Z+wlSeqcsZckqXPGXpKkzhl7SZI6Z+wlSeqcsZckqXPGXpKkzhl7SZI6Z+wlSeqcsZckqXPGXpKkzhl7SZI6Z+wlSeqcsZckqXPGXpKkzhl7SZI6Z+wlSeqcsZckqXPGXpKkzhl7SZI6Z+wlSeqcsZckqXPGXpKkzhl7SZI6Z+wlSeqcsZckqXPGXpKkzhl7SZI6Z+wlSeqcsZckqXPGXpKkzhl7SZI6Z+wlSeqcsZckqXNji32Sk5N8Kcn9SXYk+eU2/v4ku5Jsb1/nDu3zviSzSR5McvbQ+DltbDbJ5eOasyRJPVo5xmPvBd5bVXcneRGwLcnWtu6qqvrw8MZJTgUuAF4JvBz4QpJXtNUfA94M7ATuSrK5qu4f49wlSerG2GJfVY8Bj7XlbyV5AFh1iF3WAzdX1TPA15PMAqe3dbNV9TBAkpvbtsZekqQRLMlr9knWAK8BvtaGLktyT5JNSY5vY6uAR4d229nGDjZ+4HNsTDKTZGZubm6xfwRJkibW2GOf5IXArcB7quqbwLXAjwLrGJz5f2Qxnqeqrquq6aqanpqaWoxDSpLUhXG+Zk+SYxiE/pNV9QcAVfXE0PrfAz7fHu4CTh7afXUb4xDjkiTpMMZ5N36A64EHquqjQ+MnDW3288B9bXkzcEGS5yY5BVgL3AncBaxNckqSYxncxLd5XPOWJKk34zyzfwPwDuDeJNvb2K8CFyZZBxTwCPAugKrakeQWBjfe7QUurap9AEkuA24DVgCbqmrHGOctSVJXxnk3/h8DmWfVlkPscyVw5TzjWw61nyRJOjjfQU+SpM4Ze0mSOmfsJUnqnLGXJKlzxl6SpM4Ze0mSOmfsJUnqnLGXJKlzxl6SpM4Ze0mSOmfsJUnqnLGXJKlzxl6SpM4Ze0mSOmfsJUnqnLGXJKlzxl6SpM4Ze0mSOmfsJUnqnLGXJKlzxl6SpM4Ze0mSOmfsJUnqnLGXJKlzxl6SpM4Ze0mSOmfsJUnqnLGXJKlzxl6SpM4Ze0mSOmfsJUnqnLGXJKlzxl6SpM4Ze0mSOmfsJUnqnLGXJKlzxl6SpM4Ze0mSOmfsJUnqnLGXJKlzxl6SpM4Ze0mSOmfsJUnq3Nhin+TkJF9Kcn+SHUl+uY2/NMnWJA+178e38SS5OslsknuSnDZ0rA1t+4eSbBjXnCVJ6tE4z+z3Au+tqlOBM4BLk5wKXA7cXlVrgdvbY4C3AGvb10bgWhj8cQBcAbwOOB24Yv8fCJIk6fDGFvuqeqyq7m7L3wIeAFYB64Eb22Y3Aue15fXATTVwB3BckpOAs4GtVbWnqp4CtgLnjGvekiT1Zkles0+yBngN8DXgxKp6rK16HDixLa8CHh3abWcbO9i4JEkawdhjn+SFwK3Ae6rqm8PrqqqAWqTn2ZhkJsnM3NzcYhxSkqQujDX2SY5hEPpPVtUftOEn2uV52vfdbXwXcPLQ7qvb2MHG/56quq6qpqtqempqanF/EEmSJtg478YPcD3wQFV9dGjVZmD/HfUbgM8NjV/U7so/A3i6Xe6/DTgryfHtxryz2pgkSRrByjEe+w3AO4B7k2xvY78KfAi4JcklwDeAt7V1W4BzgVngu8DFAFW1J8kHgbvadh+oqj1jnLckSV0ZW+yr6o+BHGT1mfNsX8ClBznWJmDT4s1OkqSjh++gJ0lS54y9JEmdM/aSJHXO2EuS1DljL0lS54y9JEmdM/aSJHXO2EuS1DljL0lS54y9JEmdM/aSJHXO2EuS1DljL0lS54y9JEmdM/aSJHXO2EuS1DljL0lS54y9JEmdM/aSJHXO2EuS1DljL0lS54y9JEmdM/aSJHXO2EuS1DljL0lS54y9JEmdM/aSJHXO2EuS1DljL0lS54y9JEmdGyn2SW4fZUySJB15Vh5qZZLnAT8EnJDkeCBt1YuBVWOemyRJWgSHjD3wLuA9wMuBbXwv9t8Efnt805IkSYvlkLGvqt8CfivJu6vqmiWakyRJWkSHO7MHoKquSfKTwJrhfarqpjHNS5IkLZKRYp/kE8CPAtuBfW24AGMvSdIRbqTYA9PAqVVV45yMJElafKP+O/v7gH8wzolIkqTxGPXM/gTg/iR3As/sH6yqnxvLrCRJ0qIZNfbvH+ckJEnS+Ix6N/6Xxz0RSZI0HqPejf8tBnffAxwLHAN8p6pePK6JSZKkxTHqmf2L9i8nCbAeOGNck5IkSYtnwZ96VwN/CJy9+NORJEmLbdRPvXvr0Nf5ST4E/N/D7LMpye4k9w2NvT/JriTb29e5Q+vel2Q2yYNJzh4aP6eNzSa5/Fn8jJIkHdVGvRv/Z4eW9wKPMLiUfyg3MPiwnAPfZe+qqvrw8ECSU4ELgFcy+NCdLyR5RVv9MeDNwE7griSbq+r+EectSdJRb9TX7C9e6IGr6itJ1oy4+Xrg5qp6Bvh6klng9LZutqoeBkhyc9vW2EuSNKJRL+OvTvLZdll+d5Jbk6x+ls95WZJ72mX+49vYKuDRoW12trGDjc83x41JZpLMzM3NPcupSZLUn1Fv0Ps4sJnBJfaXA/+1jS3UtQw+UGcd8BjwkWdxjHlV1XVVNV1V01NTU4t1WEmSJt6osZ+qqo9X1d72dQOw4KJW1RNVta+q/hb4Pb53qX4XcPLQpqvb2MHGJUnSiEaN/ZNJ3p5kRft6O/DkQp8syUlDD3+ewQfswOCqwQVJnpvkFGAtcCdwF7A2ySlJjmVwE9/mhT6vJElHs1Hvxv+XwDXAVQzeSe9PgXceaocknwLeCJyQZCdwBfDGJOvaMR4B3gVQVTuS3MLgxru9wKVVta8d5zLgNmAFsKmqdoz800mSpJFj/wFgQ1U9BZDkpcCHGfwRMK+qunCe4esPsf2VwJXzjG8Btow4T0mSdIBRL+O/an/oAapqD/Ca8UxJkiQtplFj/5yhfya3/8x+1KsCkiRpGY0a7I8AX03ymfb4F5nnkrskSTryjPoOejclmQHe1Ibe6lvWSpI0GUa+FN/ibuAlSZowC/6IW0mSNFmMvSRJnTP2kiR1zthLktQ5Yy9JUueMvSRJnTP2kiR1zthLktQ5Yy9JUueMvSRJnTP2kiR1zthLktQ5Yy9JUueMvSRJnTP2kiR1zthLktQ5Yy9JUueMvSRJnTP2kiR1zthLktQ5Yy9JUueMvSRJnTP2kiR1zthLktQ5Yy9JUueMvSRJnTP2kiR1zthLktQ5Yy9JUueMvSRJnTP2kiR1zthLktQ5Yy9JUueMvSRJnTP2kiR1zthLktQ5Yy9JUueMvSRJnRtb7JNsSrI7yX1DYy9NsjXJQ+378W08Sa5OMpvkniSnDe2zoW3/UJIN45qvJEm9GueZ/Q3AOQeMXQ7cXlVrgdvbY4C3AGvb10bgWhj8cQBcAbwOOB24Yv8fCJIkaTRji31VfQXYc8DweuDGtnwjcN7Q+E01cAdwXJKTgLOBrVW1p6qeArby/X9ASJKkQ1jq1+xPrKrH2vLjwIlteRXw6NB2O9vYwcYlSdKIlu0GvaoqoBbreEk2JplJMjM3N7dYh5UkaeItdeyfaJfnad93t/FdwMlD261uYwcb/z5VdV1VTVfV9NTU1KJPXJKkSbXUsd8M7L+jfgPwuaHxi9pd+WcAT7fL/bcBZyU5vt2Yd1YbkyRJI1o5rgMn+RTwRuCEJDsZ3FX/IeCWJJcA3wDe1jbfApwLzALfBS4GqKo9ST4I3NW2+0BVHXjTnyRJOoSxxb6qLjzIqjPn2baASw9ynE3ApkWcmiRJRxXfQU+SpM4Ze0mSOmfsJUnqnLGXJKlzxl6SpM4Ze0mSOmfsJUnqnLGXJKlzxl6SpM4Ze0mSOmfsJUnqnLGXJKlzxl6SpM4Ze0mSOmfsJUnqnLGXJKlzxl6SpM4Ze0mSOmfsJUnqnLGXJKlzxl6SpM4Ze0mSOmfsJUnqnLGXJKlzxl6SpM4Ze0mSOmfsJUnqnLGXJKlzxl6SpM4Ze0mSOmfsJUnqnLGXJKlzxl6SpM4Ze0mSOmfsJUnqnLGXJKlzxl6SpM4Ze0mSOmfsJUnqnLGXJKlzxl6SpM4Ze0mSOmfsJUnqnLGXJKlzyxL7JI8kuTfJ9iQzbeylSbYmeah9P76NJ8nVSWaT3JPktOWYsyRJk2o5z+x/uqrWVdV0e3w5cHtVrQVub48B3gKsbV8bgWuXfKaSJE2wI+ky/nrgxrZ8I3De0PhNNXAHcFySk5ZhfpIkTaTlin0B/yPJtiQb29iJVfVYW34cOLEtrwIeHdp3Zxv7e5JsTDKTZGZubm5c85YkaeKsXKbn/amq2pXkZcDWJH8xvLKqKkkt5IBVdR1wHcD09PSC9pUkqWfLcmZfVbva993AZ4HTgSf2X55v33e3zXcBJw/tvrqNSZKkESx57JO8IMmL9i8DZwH3AZuBDW2zDcDn2vJm4KJ2V/4ZwNNDl/slSdJhLMdl/BOBzybZ//y/X1X/PcldwC1JLgG+Abytbb8FOBeYBb4LXLz0U5YkaXIteeyr6mHg1fOMPwmcOc94AZcuwdQkSerSkfRP7yRJ0hgYe0mSOmfsJUnqnLGXJKlzxl6SpM4Ze0mSOmfsJUnqnLGXJKlzxl6SpM4Ze0mSOmfsJUnqnLGXJKlzxl6SpM4Ze0mSOmfsJUnqnLGXJKlzxl6SpM4Ze0mSOmfsJUnqnLGXJKlzxl6SpM4Ze0mSOmfsJUnqnLGXJKlzxl6SpM4Ze0mSOmfsJUnqnLGXJKlzxl6SpM4Ze0mSOmfsJUnqnLGXJKlzxl6SpM4Ze0mSOmfsJUnqnLGXJKlzxl6SpM4Ze0mSOmfsJUnqnLGXJKlzxl6SpM4Ze0mSOmfsJUnq3MTEPsk5SR5MMpvk8uWejyRJk2IiYp9kBfAx4C3AqcCFSU5d3llJkjQZJiL2wOnAbFU9XFV/A9wMrF/mOUmSNBEmJfargEeHHu9sY5Ik6TBWLvcEFkuSjcDG9vDbSR5czvnoB3IC8JfLPYme5cMblnsKOjL5u7cUrsi4jvwPD7ZiUmK/Czh56PHqNvZ3quo64LqlnJTGI8lMVU0v9zyko42/e/2alMv4dwFrk5yS5FjgAmDzMs9JkqSJMBFn9lW1N8llwG3ACmBTVe1Y5mlJkjQRJiL2AFW1Bdiy3PPQkvDlGGl5+LvXqVTVcs9BkiSN0aS8Zi9Jkp4lY68jim+LLC29JJuS7E5y33LPReNh7HXE8G2RpWVzA3DOck9C42PsdSTxbZGlZVBVXwH2LPc8ND7GXkcS3xZZksbA2EuS1DljryPJYd8WWZK0cMZeRxLfFlmSxsDY64hRVXuB/W+L/ABwi2+LLI1fkk8BXwX+cZKdSS5Z7jlpcfkOepIkdc4ze0mSOmfsJUnqnLGXJKlzxl6SpM4Ze0mSOmfspQmTZF+S7Ul2JPnzJO9NckT/LieZSvK1JH+W5J8dsO5/Jpk+zP7/OslF452l1K+Vyz0BSQv211W1DiDJy4DfB14MXPGDHjjJiqra94MeZx5nAvdW1b96NjtX1e8uZPskK9v7NkjCM3tpolXVbmAjcFkGViT5zSR3JbknybsAkjwnye8k+YskW5NsSXJ+W/dIkt9Icjfwi0nOSvLVJHcn+UySF7btXpvky0m2JbktyUkHzifJmiRfbM99e5IfSbIO+I/A+nZF4vkH+3mSfDvJle2KxR1JTmzj70/y79ry310JSHJCkkfa8juTbE7yReD2JDclOW/o2J9M4qco6qhk7KUJV1UPAyuAlwGXAE9X1U8APwH8UpJTgLcCa4BTgXcArz/gME9W1WnAF4BfA36mPZ4B/m2SY4BrgPOr6rXAJuDKeaZzDXBjVb0K+CRwdVVtB34d+HRVrauqvz7Ej/MC4I6qejXwFeCXFvQfA05rc/znwPXAOwGSvAT4SeC/LfB4Uhe8jC/15SzgVfvP2oGXAGuBnwI+U1V/Czye5EsH7Pfp9v0MBn8Q/EkSgGNpb6MK/FNgaxtfATw2z/O/nsEfFgCfYHBGvxB/A3y+LW8D3rzA/bdW1R6Aqvpyu5oxBfwCcKuX9nW0MvbShEvyj4B9wG4gwLur6rYDtjn3MIf5zv5NGQTzwgP2/3FgR1UdeEVgsf2/+t57eO9j/v9H7eV7VyWfd8C67xzw+Cbg7Qw+VOnixZqkNGm8jC9NsHbW+rvAb7dI3gb8m3bZnSSvSPIC4E+AX2iv3Z8IvPEgh7wDeEOSH2v7vyDJK4AHgakkr2/jxyR55Tz7/ymDsAL8C+CPFuPnPMAjwGvb8vmH2A7gBuA9AFV1/xjmIk0Ez+ylyfP8JNuBYxic5X4C+Ghb958ZvDZ/dwbX2+eA84BbGdwRfz/wKHA38PSBB66quSTvBD6V5Llt+Neq6n+1lwaubq9/rwT+E3DgpxK+G/h4kl9pz72YZ9P7z/g/DNySZCOHeQ2+qp5I8gDwh4s4D2ni+Kl30lEiyQur6ttJfhi4E3hDVT2+3PMaRZJrgLur6uML3O+HgHuB06rq+/64kY4WXsaXjh6fb1cE/gj44ASF/oPA64DNC9zvZ4AHgGsMvY52ntlLktQ5z+wlSeqcsZckqXPGXpKkzhl7SZI6Z+wlSeqcsZckqXP/H9k9G2ZoDvdwAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dividindo o dataset em uma parte que representa as variáveis independentes (features) e uma parte que representa  uma variável dependnete (target).\n",
    "X = df.drop('Degree of Injury', axis = 1)\n",
    "y = df['Degree of Injury']\n",
    "\n",
    "# Balanceando as classes criando uma amostra da classe '0'.\n",
    "Over_sampler = RandomOverSampler()\n",
    "X0, y0 = Over_sampler.fit_resample(X, y)\n",
    "\n",
    "# Plotando as classes balanceadas\n",
    "plt.figure(figsize=(8, 6))\n",
    "np.bincount(y0)\n",
    "ax = sns.countplot(x=y0)\n",
    "\n",
    "# Normalizando as features\n",
    "scaler = MinMaxScaler()\n",
    "X =  scaler.fit_transform(X0)\n",
    "X = pd.DataFrame(X0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Machine Learning <a id= \"3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primeiro Nível <a id= \"4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mLoss Médio do XGB: 0.1755\n",
      "\u001b[34mROC-AUC Médio do XGB: 93.51%\n",
      "\u001b[34mLoss Médio do CatBoost: 0.1840\n",
      "\u001b[34mROC-AUC Médio do CatBoost: 93.11%\n",
      "\u001b[34mLoss Médio do LightGBM: 0.1716\n",
      "\u001b[34mROC-AUC Médio do LightGBM: 93.79%\n",
      "\u001b[32mLoss Médio Total: 0.1770\n",
      "\u001b[32mROC-AUC Médio Total: 93.47%\n"
     ]
    }
   ],
   "source": [
    "# Dedinindo o conjunto de modelos de nível um.\n",
    "\n",
    "# Criando um cross-validation de 4 splits.\n",
    "kf = KFold(n_splits= 4, shuffle=True, random_state=0)\n",
    "\n",
    "# Definindo listas vazias\n",
    "xgb1 = []\n",
    "rocl = []\n",
    "cat1 = []\n",
    "rocl2 = []\n",
    "light1 = []\n",
    "rocl3 = []\n",
    "\n",
    "# Criando um matriz de zeros para amazenar os resultados das previsões dos modelos de primeiro nível.\n",
    "second_level = np.zeros((X.shape[0], 3))\n",
    "\n",
    "# Definindo as linhas de treino e validação \n",
    "for i, (tr, ts) in enumerate(kf.split(X)):\n",
    "    Xtr, ytr = X.iloc[tr], y0.iloc[tr]\n",
    "    Xval, yval = X.iloc[ts], y0.iloc[ts]\n",
    "    \n",
    "    # Usamos o XGBClassifier com os hiperparâmetros previamente otimizados como priemiro modelo.\n",
    "    xgb = XGBClassifier(random_state=123, \n",
    "                            n_estimators = 800,\n",
    "                            learning_rate=0.08,\n",
    "                            max_depth = 4,\n",
    "                            subsample = 0.8,\n",
    "                            verbosity = 0)\n",
    "    \n",
    "    # Treinando o XGBClassifier\n",
    "    xgb.fit(Xtr, ytr)\n",
    "    \n",
    "    # Criando valores de predição do XGBClassifier com dados de validação \n",
    "    p1 = xgb.predict(Xval)\n",
    "\n",
    "    # Criando predições em termos de porcentagem da classes previstas\n",
    "    sec1 = xgb.predict_proba(Xval)\n",
    "    \n",
    "    \n",
    "    # Calculando a função de log loss do modelo XGBClassifier.\n",
    "    ll = log_loss(yval, sec1)\n",
    "    \n",
    "    # Calculando o valor da métrica ROC-AUC\n",
    "    roc = roc_auc_score(yval, p1)\n",
    "\n",
    "    # Armazenando os valores de ROC-AUC em uma lista para cada split\n",
    "    rocl.append(roc)\n",
    "    \n",
    "    # Armazenando os valores da log loss em uma lista para cada split\n",
    "    xgb1.append(ll)\n",
    "\n",
    "    # Usamos o CatBoostClassifier com os hiperparâmetros previamente otimizados como segundo modelo.\n",
    "    cat = CatBoostClassifier(\n",
    "        random_state=123,\n",
    "        learning_rate= 0.009,\n",
    "        l2_leaf_reg= 0.18,\n",
    "        max_depth= 7,\n",
    "        n_estimators= 1000,\n",
    "        verbose=0)\n",
    "    \n",
    "    # Treinando o CatBoostClassifier\n",
    "    cat.fit(Xtr, ytr)\n",
    "\n",
    "    # Criando valores de predição do CatBoostClassifier com dados de validação \n",
    "    p2 = cat.predict(Xval)\n",
    "\n",
    "    # Criando predições em termos de porcentagem da classes previstas\n",
    "    sec2 = cat.predict_proba(Xval)\n",
    "    \n",
    "     \n",
    "    # Calculando a função de log loss do modelo CatBoostClassifier.\n",
    "    ll2 = log_loss(yval, sec2)\n",
    "    \n",
    "    # Calculando o valor da métrica ROC-AUC\n",
    "    roc2 = roc_auc_score(yval, p2)\n",
    "    \n",
    "    # Armazenando os valores de ROC-AUC em uma lista para cada split\n",
    "    rocl2.append(roc2)\n",
    "    \n",
    "    # Armazenando os valores da log loss em uma lista para cada split\n",
    "    cat1.append(ll2)\n",
    "    \n",
    "    # Usamos o LGBMClassifier com os hiperparâmetros previamente otimizados como terceiro modelo.\n",
    "    lgbm = lgb.LGBMClassifier(\n",
    "                                random_state=123,\n",
    "                                n_estimators = 1500, \n",
    "                                learning_rate=0.008, \n",
    "                                max_depth=12, \n",
    "                                subsample = 0.8, \n",
    "                                colsample_bytree=0.8,\n",
    "                                n_jobs=6)\n",
    "    # Treinando o LGBMClassifier\n",
    "    lgbm.fit(Xtr, ytr)\n",
    "    \n",
    "    # Criando valores de predição do LGBMClassifier com dados de validação \n",
    "    p3 = lgbm.predict(Xval)\n",
    "\n",
    "    # Criando predições em termos de porcentagem da classes previstas\n",
    "    sec3 = lgbm.predict_proba(Xval)\n",
    "    \n",
    "    # Calculando a função de log loss do modelo LGBMClassifier.\n",
    "    ll_lgbm = log_loss(yval, sec3)\n",
    "\n",
    "    # Calculando o valor da métrica ROC-AUC\n",
    "    roc3 = roc_auc_score(yval, p3)\n",
    "    \n",
    "    # Armazenando os valores da log loss em uma lista para cada split\n",
    "    light1.append(ll_lgbm)\n",
    "\n",
    "    # Armazenando os valores de ROC-AUC em uma lista para cada split\n",
    "    rocl3.append(roc3)\n",
    "    \n",
    "    # Preenchendo a matriz second_level com valores preditos para os três modelos.\n",
    "    second_level[ts, 0] = sec1[:, 1]\n",
    "    second_level[ts, 1] = sec2[:, 1]\n",
    "    second_level[ts, 2] = sec3[:, 1]\n",
    "\n",
    "# criando listas para armazenar os valores das log loss e ROC-AUC de todos os modelos.\n",
    "loss_tot = [ (a + b + c) for a, b, c in zip(xgb1, cat1, light1) ]\n",
    "roc_tot = [ (a + b + c) for a, b, c in zip(rocl, rocl2, rocl3) ]\n",
    "\n",
    "print(Fore.BLUE + \"Loss Médio do XGB: {:.4f}\".format(np.mean(xgb1)))\n",
    "print(Fore.BLUE + \"ROC-AUC Médio do XGB: {:.2f}%\".format(100*np.mean(rocl)))\n",
    "\n",
    "print(Fore.BLUE + \"Loss Médio do CatBoost: {:.4f}\".format(np.mean(cat1)))\n",
    "print(Fore.BLUE + \"ROC-AUC Médio do CatBoost: {:.2f}%\".format(100*np.mean(rocl2)))\n",
    "\n",
    "print(Fore.BLUE + \"Loss Médio do LightGBM: {:.4f}\".format(np.mean(light1)))\n",
    "print(Fore.BLUE + \"ROC-AUC Médio do LightGBM: {:.2f}%\".format(100*np.mean(rocl3)))\n",
    "\n",
    "print(Fore.GREEN + \"Loss Médio Total: {:.4f}\".format(np.mean(loss_tot)/3))\n",
    "print(Fore.GREEN + \"ROC-AUC Médio Total: {:.2f}%\".format(100*np.mean(roc_tot)/3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtivemos um valor de log-loss médio de 0.1770 e ROC-AUC médio de 93.73% devido a contribuição de todos os modelos de primeiro nível. O que pretendemos no segundo nível é obter um desempenho igual ou bem próximo dos valores das métricas obtidas no primeiro nível."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segundo Nível <a id= \"5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mLoss Médio do LightGBM: 0.1780\n",
      "\u001b[32mROC-AUC Médio do LightGBM: 9.4e+01%\n"
     ]
    }
   ],
   "source": [
    "# Criando modelo de segundo nível\n",
    "\n",
    "# Criando listas vazias para armazenar os valores das log loss e ROC-AUC\n",
    "ll_stacks = []\n",
    "rocl_stacks = []\n",
    "\n",
    "for tr, ts in kf.split(X,y0):\n",
    "    \n",
    "    # Aqui usamos os valores preditos pelos modelos em primeiro nível como features de treino e validação no segundo nível. \n",
    "    Xtr, Xval = second_level[tr], second_level[ts]\n",
    "    ytr, yval = y0.iloc[tr], y0.iloc[ts]\n",
    "    \n",
    "    # Usaremos um modelo de Logistic Regression para treinar \n",
    "    ls_stack = LogisticRegression(C = 1.)\n",
    "\n",
    "    # Treinando o modelo com dados de primeiro nível\n",
    "    ls_stack.fit(Xtr, ytr)\n",
    "    \n",
    "    # Criando valores de predição com dados de validação da logistic regression\n",
    "    pls_stack = ls_stack.predict(Xval)\n",
    "\n",
    "    # Criando predições em termos de porcentagem da classes previstas\n",
    "    sec_stack = ls_stack.predict_proba(Xval)\n",
    "    \n",
    "    # Calculando a função de log loss do modelo Logistic Regression.\n",
    "    ll_stack = log_loss(yval, sec_stack)\n",
    "\n",
    "    # Calculando o valor da métrica ROC-AUC\n",
    "    roc_stack = roc_auc_score(yval, pls_stack) \n",
    "    \n",
    "    # Armazenando os valores da log loss em uma lista para cada split\n",
    "\n",
    "    ll_stacks.append(ll_stack)\n",
    "\n",
    "    # Armazenando os valores de ROC-AUC em uma lista para cada split\n",
    "    rocl_stacks.append(roc_stack)\n",
    "\n",
    "print(Fore.GREEN + \"Loss Médio do LightGBM: {:.4f}\".format(np.mean(ll_stacks)))\n",
    "print(Fore.GREEN + \"ROC-AUC Médio do LightGBM: {:.2}%\".format(100*np.mean(rocl_stacks)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando os valores das métricas no primeiro e segundo nível:\n",
    "* A Log-Loss média do primeiro nível foi de 0.1770.\n",
    "* A Log-Loss média do segundo nível foi de 0.1780. \n",
    "--------------------------------------------------\n",
    "* O ROC-AUC médio do primeiro nível foi de 93.47%. \n",
    "* O ROC-AUC médio do segundo nível foi de 94.00%.  \n",
    "\n",
    "Ao compararmos os desempenhos dos modelos nos dois níveis, vemos que a log-loss no primeiro nível foi um pouco melhor do que no segundo nível. Em quando que a ROC-AUC teve valor um pouco melhor que a média de todos os modelos de primeiro nível. Este resultado já mostra que nosso esemble é melhor que média dos modelos inviduais como também é mais confiável ter uma sistema de classificação que trabalha com base na previsão conjunta de muitos modelos. Embora os valores destas métricas devem flutuar sempre que notebook é rodado, devemos esperar que os valores de segundo nível sejam melhores do que no primeiro nível."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando Dataframe Com as Previsões <a id= \"6\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando dataframe com valores reais e previstos para o 'nivel de lesão' do empregado.\n",
    "p = pd.DataFrame(pls_stack)\n",
    "ps = pd.DataFrame(yval)\n",
    "ps = ps.reset_index(drop = True)\n",
    "sof = pd.concat([ps, p], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renomeando as colunas dos valores reais e prevsitos.\n",
    "sof = sof.rename(columns={'Degree of Injury': 'Degree of Injury Real', 0 : 'Degree of Injury Preditions'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Degree of Injury Real</th>\n",
       "      <th>Degree of Injury Preditions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Degree of Injury Real  Degree of Injury Preditions\n",
       "0                      0                            0\n",
       "1                      1                            1\n",
       "2                      1                            1\n",
       "3                      1                            1\n",
       "4                      1                            1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostrando a comparação entre valores reais e preditos.\n",
    "sof.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão <a id= \"7\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fomos bem sucedidos em criar um ensemble de machine learning para prever se determinado empregado pode sofrer um acidente letal. Utilizando um esquema de stacking de apenas dois níveis, composto de um modelo XGBClassifier, CatBoostClassifier e LGBMClassifier no primeiro nível e LogisticRegression no segundo nível. Obtendo 94.0% de ROC-AUC na confiabilidade de separação das classes e 0.1780 de log-loss. Sendo estes resultados mais confiáveis do que os mesmos valores se tivessem sidos obtidos por um único modelo. De modo geral nosso experiemento se mostra promissor em aplicarmos modelos do tipo ensemble para produção em larga escala e desse modo auxiliar na prevenção de graves acidentes.\n",
    "\n",
    "Nosso próximo passo é melhorar o desempenho do nosso modelo preditivo. As abordagens mais diretas que podemos usar é adicionar mais modelos de classificação no priemiro nível e ao mesmo tempo aumentar os niveis de validação. Além disso, podemos tunar os hiperparâmetros de todos os modelos em todos os níveis. Uma abordagem que pode se mostrar muito poderosa é usarmos técnicas de automl como pycaret para gerarmos os modelos mais eficientes e implementarmos em todos os níveis com os hiperparâmetros já tunados."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "70bbc14ac656fae6255699fdfbb0a219fec5e7446bcca062721a0f399f9119ed"
  },
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
