# Prevendo a Ocorrência de Graves Acidentes de Trabalho Usando a Técnica Ensembles de Machine Learning

Desenvolver um ambiente de trabalho protetor e o mais seguro possível é um dos principais desafios enfrentados pelas companhias. Principalmente Em setores pesados da indústria, onde o risco de acidente fatal é bem maior que nos demais setores. Naturalmente, a busca de ambiente de trabalho com alta prioridade de segurança pode custar um parte significativa da receita de uma companhia. Logo, buscar novas técnicas e tecnologias que aumente a eficiência da gestão de segurança do trabalho e ao mesmo tempo reduza os custos de implementação é imprescindível. Com este intuito, construir modelos de previsão que possam mostrar a probabilidade de ocorrência de determinados eventos de risco é uma estratégia muito empregada atualmente. Modelos de machine learning são muito bons em classificar e prever a probabilidade de eventos de risco. Contudo, devido a natureza delicada de se prever a possibilidade de um funcionário sofrer um acidente fatal, precisamos de modelos realmente confiáveis. Sabemos que um único modelo de machine laerning esta sujeito a eventos que podem reduzir ou invalidar suas previsões. Entre esses eventos temos os mais comuns que são o overfiting e underfiting. Além disso temos a possiblidade das features do dataset ser bastante heterogênea de modo que o modelo pode ter um desempenho melhor para determinadas partes do dataset do que em outras. 

Nosso objetivo é construir um modelo de classificação que possa prever com alta confiabilidade o 'grau de lesão' evitando a maioria dos problemas citados acima. Por isso faremos uso de esemble de machine learnig do tipo stacking que usa a previsão de vários modelos de machine leaining para gerar dados para validação posterior de outros modelos. Normalmente quando queremos validar informações que possuímos comparamos com outras fontes que possuem a mesma informação. Para uma visão mais detalhada do conceito ensemble pode ser encontrado aqui: [ensemble-learning-bagging-boosting-stacking](https://www.kaggle.com/satishgunjal/ensemble-learning-bagging-boosting-stacking). Quanto mais fontes puderem validar a nossa informação prévia mais certos estaremos. Esta é a forma básica de como a técnica dos esembles funciona, com isso esperamos aumentar a confiança na previsão dos nossos modelos. Mais especificamente nosso esemble terá dois níveis, onde rodamos um conjunto de modelos no primeiro nível e usamos as predições deste nível para treinar um modelo no segundo nível. De modo que o modelo de segundo nível deve ter um desepenho melhor e mais confiável que um único modelo.

A nossa base de dados que usaremos neste notebook foi obtida do dataset original onde este consistia de uma série de colunas categóricas e numéricas que mostrava várias informações sobre os empregados que sofreram lesões fatais e não-fatais. O dataset original pode encontrado neste link: [Osha-accident-and-injury-data](https://www.kaggle.com/ruqaiyaship/osha-accident-and-injury-data-1517). Após as transformações adequadas para a limpeza do dataset, convertemos as features categóricas em novas colunas usando o OneHotEncoder(). Com os dados limpos em mãos tentaremos responder a seguinte questão: dado uma série de features associadas a um empregado que sofreu um acidente qual probabilidade do mesmo sobreviver ou não ao um determinado acidente de trabalho. Para avaliar todos os modelos utilizados neste notebook usaremos a métrica log-loss e a métrica ROC-AUC. A log-loss é a melhor métrica para avaliar classificação com base nas probabilidades das previsões. Além disso a log-loss é muito boa para compararmos modelos com outros, quando menor o valor da log-loss melhor será o modelo. Já ROC-AUC basicamente nos diz o quão bem o modelo conseguie separar as classes alvos. 50% de ROC-AUC significa que o modelo não consegue distinguir entre as classes alvos, enquanto que  em 100% o modelo separa com perfeição as classes alvos.
