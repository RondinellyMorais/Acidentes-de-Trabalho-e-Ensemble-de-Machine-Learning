# Prevendo a Ocorrência de Graves Acidentes de Trabalho Usando a Técnica Ensembles de Machine Learning
![Ensemble](https://github.com/RondinellyMorais/Acidentes-de-Trabalho-e-Ensemble-de-Machine-Learning/blob/master/esemble.png)

Desenvolver um ambiente de trabalho protetor e o mais seguro possível é um dos principais desafios enfrentados pelas companhias. Principalmente Em setores pesados da indústria, onde o risco de acidente fatal é bem maior que nos demais setores. Naturalmente, a busca de ambiente de trabalho com alta prioridade de segurança pode custar um parte significativa da receita de uma companhia. Logo, buscar novas técnicas e tecnologias que aumente a eficiência da gestão de segurança do trabalho e ao mesmo tempo reduza os custos de implementação é imprescindível. Com este intuito, construir modelos de previsão que possam mostrar a probabilidade de ocorrência de determinados eventos de risco é uma estratégia muito empregada atualmente. Modelos de machine learning são muito bons em classificar e prever a probabilidade de eventos de risco. Contudo, devido a natureza delicada de se prever a possibilidade de um funcionário sofrer um acidente fatal, precisamos de modelos realmente confiáveis. Sabemos que um único modelo de machine laerning esta sujeito a eventos que podem reduzir ou invalidar suas previsões. Entre esses eventos temos os mais comuns que são o overfiting e underfiting. Além disso temos a possiblidade das features do dataset ser bastante heterogênea de modo que o modelo pode ter um desempenho melhor para determinadas partes do dataset do que em outras. 

Nosso objetivo é construir um modelo de classificação que possa prever com alta confiabilidade o 'grau de lesão' evitando a maioria dos problemas citados acima. Por isso faremos uso de esemble de machine learnig do tipo stacking que usa a previsão de vários modelos de machine leaining para gerar dados para validação posterior de outros modelos. Normalmente quando queremos validar informações que possuímos comparamos com outras fontes que possuem a mesma informação. Para uma visão mais detalhada do conceito ensemble pode ser encontrado aqui: [ensemble-learning-bagging-boosting-stacking](https://www.kaggle.com/satishgunjal/ensemble-learning-bagging-boosting-stacking). Quanto mais fontes puderem validar a nossa informação prévia mais certos estaremos. Esta é a forma básica de como a técnica dos esembles funciona, com isso esperamos aumentar a confiança na previsão dos nossos modelos. Mais especificamente nosso esemble terá dois níveis, onde rodamos um conjunto de modelos no primeiro nível e usamos as predições deste nível para treinar um modelo no segundo nível. De modo que o modelo de segundo nível deve ter um desepenho melhor e mais confiável que um único modelo.

A nossa base de dados que usaremos neste notebook foi obtida do dataset original onde este consistia de uma série de colunas categóricas e numéricas que mostrava várias informações sobre os empregados que sofreram lesões fatais e não-fatais. O dataset original pode encontrado neste link: [Osha-accident-and-injury-data](https://www.kaggle.com/ruqaiyaship/osha-accident-and-injury-data-1517). Após as transformações adequadas para a limpeza do dataset, convertemos as features categóricas em novas colunas usando o OneHotEncoder(). Com os dados limpos em mãos tentaremos responder a seguinte questão: dado uma série de features associadas a um empregado que sofreu um acidente qual probabilidade do mesmo sobreviver ou não ao um determinado acidente de trabalho. Para avaliar todos os modelos utilizados neste notebook usaremos a métrica log-loss e a métrica ROC-AUC. A log-loss é a melhor métrica para avaliar classificação com base nas probabilidades das previsões. Além disso a log-loss é muito boa para compararmos modelos com outros, quando menor o valor da log-loss melhor será o modelo. Já ROC-AUC basicamente nos diz o quão bem o modelo conseguie separar as classes alvos. 50% de ROC-AUC significa que o modelo não consegue distinguir entre as classes alvos, enquanto que  em 100% o modelo separa com perfeição as classes alvos.

Comparando os valores das métricas no primeiro e segundo nível:
* A Log-Loss média do primeiro nível foi de 0.1770.
* A Log-Loss média do segundo nível foi de 0.1780. 
--------------------------------------------------
* O ROC-AUC médio do primeiro nível foi de 93.47%. 
* O ROC-AUC médio do segundo nível foi de 94.00%.  

Ao compararmos os desempenhos dos modelos nos dois níveis, vemos que a log-loss no primeiro nível foi um pouco melhor do que no segundo nível. Em quando que a ROC-AUC teve valor um pouco melhor que a média de todos os modelos de primeiro nível. Este resultado já mostra que nosso esemble é melhor que média dos modelos inviduais como também é mais confiável ter uma sistema de classificação que trabalha com base na previsão conjunta de muitos modelos. Embora os valores destas métricas devem flutuar sempre que notebook é rodado, devemos esperar que os valores de segundo nível sejam melhores do que no primeiro nível.

Fomos bem sucedidos em criar um ensemble de machine learning para prever se determinado empregado pode sofrer um acidente letal. Utilizando um esquema de stacking de apenas dois níveis, composto de um modelo XGBClassifier, CatBoostClassifier e LGBMClassifier no primeiro nível e LogisticRegression no segundo nível. Obtendo 94.0% de ROC-AUC na confiabilidade de separação das classes e 0.1780 de log-loss. Sendo estes resultados mais confiáveis do que os mesmos valores se tivessem sidos obtidos por um único modelo. De modo geral nosso experiemento se mostra promissor em aplicarmos modelos do tipo ensemble para produção em larga escala e desse modo auxiliar na prevenção de graves acidentes.

Nosso próximo passo é melhorar o desempenho do nosso modelo preditivo. As abordagens mais diretas que podemos usar é adicionar mais modelos de classificação no priemiro nível e ao mesmo tempo aumentar os niveis de validação. Além disso, podemos tunar os hiperparâmetros de todos os modelos em todos os níveis. Uma abordagem que pode se mostrar muito poderosa é usarmos técnicas de automl como pycaret para gerarmos os modelos mais eficientes e implementarmos em todos os níveis com os hiperparâmetros já tunados.
